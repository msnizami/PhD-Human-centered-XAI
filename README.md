# Welcome!
I am a PhD researcher in "Explainable AI" at the University of Urbino, Italy.
The main focus of PhD research is to design and develop frameworks and tools for "Human-centered explanations" with a speacial focus on Human-centered Counterfactual Explanations for trustworthy, actioanble, and understandable AI.

### Projects
- Feedback-based Counterfactual Explanations [FCE](https://github.com/msnizami/FCE)
- Counterfactual explanation with User feedback [UFCE](https://github.com/msnizami/UFCE)
- CL-XAI Pilot Study: Toward Enhanced Cognitive Learning with Explainable AI [CL-XAI](https://arxiv.org/abs/2312.12290)
- ExpGame Large Scale study for qualitative evaluations of [UFCE]... soon be availble
- How XAI-assited Decision-Making Steer Human behaviour [click here](https://github.com/msnizami/XAI-steer-Human-Behaviour)]...soon be availble

#### Toward Enhanced Cognitive Learning with Explainable AI (CL-XAI)

An interactive game designed to enhance cognitive learning through domain-agnostic combinatorial tasks. The game is deployed on our web server, and you can access it [here](http://85.235.144.146:8888/index.html).

##### Key Objectives of CL-XAI

CL-XAI focuses on two main objectives:

1. **Understanding Human Comprehension:** Explore how human learners comprehend AI models using XAI tools.
2. **Evaluating Tool Effectiveness:** Evaluate the effectiveness of XAI tools through valuable human feedback.


#### Our other related works:
- [Toward enriched Cognitive Learning with XAI](https://arxiv.org/abs/2312.12290).
  
- [FCE: Feedback Based Counterfactual Explanations for Explainable AI](https://ieeexplore.ieee.org/document/9819899)
  
- [Investigating Human-Centered Perspectives in Explainable Artificial Intelligence](https://ceur-ws.org/Vol-3518/paper4.pdf)
  
- [Towards Human Cognition Level-based Experiment Design for Counterfactual Explanations](https://ieeexplore.ieee.org/abstract/document/9994203)
  


##### The latest research papers are listed below:
- [How to Build Self-Explaining Fuzzy Systems: From Interpretability to Explainability [AI-eXplained]](https://ieeexplore.ieee.org/document/10384509/references#references)


More research works can be found at [Google Scholar](https://scholar.google.com/citations?user=MSrYRgEAAAAJ&hl=en)

The PhD research is mentored by:
- Professor Alessandro Bogliolo (DiSpeA, University of Urbino, Italy) [Scientific works](https://scholar.google.com/citations?user=M9Ood7kAAAAJ&hl=en)
- Jose Maria Alonso-Moral (CiTIUS, University of Santiago de Compostela, Spain) [Scientific works](https://scholar.google.com/citations?user=wDMgf44AAAAJ&hl=en)
